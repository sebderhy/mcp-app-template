# ChatGPT App Template

A template for building ChatGPT Apps, designed to be edited seamlessly with AI coding agents like Claude Code (CLAUDE.md file included).

## Why This Template?

**Build ChatGPT Apps with AI assistance.** This template is structured so that AI coding agents can modify, extend, and test your app without manual intervention:

1. **Zero-config testing** - Simulator works instantly with no API key (free for dev/testing via [Puter.js](https://puter.com))
2. **Automated UI testing** - AI agents can test widgets visually using Playwright screenshots
3. **Coding Agent Onboarding** - `CLAUDE.md` explains the codebase, so AI agents know where things are
4. **Orthogonal test suite** - 282 tests that pass regardless of what app you build
5. **Local ChatGPT Simulator** - Test widgets locally without deploying to ChatGPT
6. **Working examples** - 8 widget examples to learn from or build upon

The tests verify *infrastructure*, not business logic. When you (or your AI agent) modify widgets, add features, or change data - the tests still pass. Run `pnpm run test` anytime to verify everything works, without connecting to ChatGPT.

## Demo

https://github.com/user-attachments/assets/f5877544-0dce-4c31-979e-50b5533f9a16

## Quick Start

```bash
# Clone and install
git clone https://github.com/sebderhy/chatgpt-app-template.git my-app
cd my-app
pnpm install
cd server && uv sync && cd ..

# Build and run
pnpm run build
pnpm run test     # Verify everything works
pnpm run server   # Starts on http://localhost:8000
```

Open the simulator: **http://localhost:8000/assets/simulator.html**

That's it! No API key required for testing - the simulator uses [Puter.js](https://puter.com) for free AI in development.

## Local Simulator

The simulator lets you test widgets without deploying to ChatGPT. It works in two modes:

### Zero-Config Mode (No API Key)

Just start the server and open the simulator - it works immediately:

```bash
pnpm run build
pnpm run server
# Open http://localhost:8000/assets/simulator.html
```

The simulator automatically detects when no API key is configured and uses [Puter.js](https://puter.com) - a free, browser-based AI service. This is perfect for:
- AI coding agents testing without credentials
- Quick prototyping sessions
- Demos and presentations

Note: Puter.js is only used in the local simulator. In production, your app connects to real ChatGPT which provides the AI - no Puter.js involved.

### Full Mode (With OpenAI API Key)

For production-quality testing with your preferred model:

1. Add your OpenAI API key to `.env`:
   ```bash
   OPENAI_API_KEY=sk-...
   ```

2. Optionally configure the model in `server/simulator_config.json`:
   ```json
   {
     "model": "gpt-4o-mini",
     "mcp_server_url": "http://localhost:8000/mcp"
   }
   ```

3. Restart the server and open the simulator

The simulator shows which mode is active in the header.

### Simulator Features

| Feature | Description |
|---------|-------------|
| **Zero-config mode** | Works instantly without any API key |
| **Inline widgets** | Widgets appear in chat just like real ChatGPT |
| **Expand to fullscreen** | Click the expand icon to view widgets fullscreen |
| **Theme toggle** | Test light/dark mode |
| **MCP protocol** | Uses the same protocol as real ChatGPT |

Try prompts like *"Show me a carousel of restaurants"* or *"Display a dashboard"*

## Test with Real ChatGPT

1. Enable [Developer Mode](https://platform.openai.com/docs/guides/developer-mode)
2. Run `ngrok http 8000 --host-header=rewrite`
3. Add connector in ChatGPT Settings → Connectors (ngrok URL + `/mcp`)
4. Ask: *"Show me the boilerplate widget"*

## How It Works

```
User Prompt → ChatGPT → MCP Tool Call → Python Server → Widget renders in ChatGPT
```

- **Widgets** (`src/`) - React/TypeScript UIs that render inside ChatGPT
- **Server** (`server/main.py`) - Python MCP server that handles tool calls
- **Simulator** (`src/simulator/`) - Local development UI with Puter.js fallback
- **Assets** (`assets/`) - Built widget bundles (generated by `pnpm run build`)

## Included Examples

| Widget | Description |
|--------|-------------|
| `boilerplate` | Basic interactive card with state management |
| `carousel` | Horizontal scrolling cards |
| `list` | Vertical list with thumbnails |
| `gallery` | Image grid with lightbox |
| `dashboard` | Stats and metrics display |
| `solar-system` | 3D visualization (Three.js) |
| `todo` | Task manager with drag-and-drop |
| `shop` | E-commerce cart flow |

Try them: *"Show me the carousel"*, *"Show me the dashboard"*, etc.

## Adding Your Own Widget

1. Create `src/my-widget/index.tsx` (entry point must target `my-widget-root`)
2. Add `"my-widget"` to the `targets` array in `build-all.mts`
3. Add a tool handler in `server/main.py`
4. Run `pnpm run build && pnpm run test`
5. Test in the simulator: `http://localhost:8000/assets/simulator.html`

## Testing

```bash
pnpm run test        # Run all 282 tests
pnpm run test:server # Server tests only (82)
pnpm run test:ui     # UI tests only (200)
```

**Tests are orthogonal to your app.** They verify:
- MCP protocol compliance
- OpenAI Apps SDK format requirements
- Build output structure
- React hooks work correctly

They don't verify your specific widgets, data, or business logic. Modify anything - tests still pass.

## Automated UI Testing (for AI Agents)

AI coding agents can visually test widgets using the built-in UI test tool. This enables AI agents to verify their changes work correctly by examining screenshots.

### Setup (One-time)

```bash
pnpm run setup:test   # Install Playwright browsers (~150MB)
```

### Two Testing Modes

**1. AI Mode (with OpenAI API key)** - Full AI-in-the-loop testing:
```bash
pnpm run ui-test "Show me the carousel widget"
```
The AI receives your prompt, decides which widget to show, and the tool captures the result.

**2. Direct Mode (no API key)** - Test specific widgets directly:
```bash
pnpm run ui-test --widget carousel
pnpm run ui-test --widget dashboard
```
Renders the widget without AI, useful for quick smoke tests.

### Output

Both modes save artifacts to `/tmp/ui-test/`:
- `screenshot.png` - Visual capture of the rendered widget
- `dom.json` - Structured data about what rendered
- `console.log` - Browser console output

AI agents can read the screenshot to verify widgets rendered correctly:
```
Read tool → /tmp/ui-test/screenshot.png
```

### Example Workflow (Claude Code)

```
User: "Add a new stats card to the dashboard"

Claude Code:
1. Modifies src/dashboard/index.tsx
2. Runs pnpm run build
3. Runs pnpm run ui-test --widget dashboard
4. Reads /tmp/ui-test/screenshot.png
5. Verifies the new card appears correctly
```

## Key APIs

```tsx
// Read data from server
const { title, items } = useWidgetProps({ title: "", items: [] });

// Persist state across tool calls
const [state, setState] = useWidgetState({ count: 0 });

// Respond to theme/display changes
const theme = useTheme();           // "light" | "dark"
const mode = useDisplayMode();      // "inline" | "fullscreen" | "pip"

// Call tools from widget
await window.openai.callTool("my_tool", { arg: "value" });
```

## Deployment

```bash
BASE_URL=https://your-domain.com pnpm run build
```

Deploy the Python server to any platform (Fly.io, Render, Railway, Cloud Run, etc.). Requirements: HTTPS, `/mcp` endpoint, SSE streaming support.

## Resources

- [Apps SDK Documentation](https://developers.openai.com/apps-sdk)
- [MCP Protocol](https://modelcontextprotocol.io/)
- [Apps SDK UI Components](https://openai.github.io/apps-sdk-ui/)
- [OpenAI Agents SDK](https://openai.github.io/openai-agents-python/)
- [Puter.js](https://developer.puter.com/) - Powers the simulator's zero-config mode (free for dev/testing)

## Acknowledgments

Based on [OpenAI's Apps SDK Examples](https://github.com/openai/openai-apps-sdk-examples).

## License

MIT
